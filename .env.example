# ========================================
# AILinux AI Server Backend Configuration
# ========================================

# --- Core Settings ---
# Request timeout in seconds for API calls
REQUEST_TIMEOUT=30

# Ollama backend timeout in milliseconds
OLLAMA_TIMEOUT_MS=15000

# Maximum concurrent requests to prevent backend overload
MAX_CONCURRENT_REQUESTS=8

# Request queue timeout in seconds
REQUEST_QUEUE_TIMEOUT=15

# CORS allowed origins (comma-separated)
# Add your frontend domains here
CORS_ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000,https://ailinux.me

# --- Redis (required for rate limiting) ---
# Redis connection URL for FastAPI rate limiter
REDIS_URL=redis://localhost:6379/0

# --- Local AI Backends ---
# Ollama API endpoint (required for local models)
OLLAMA_BASE=http://localhost:11434

# Stable Diffusion WebUI endpoint (required for image generation)
STABLE_DIFFUSION_URL=http://localhost:7860

# --- GPT-OSS Provider (optional) ---
# GPT-OSS API key for cloud/120b and other models
GPT_OSS_API_KEY=your-gpt-oss-key

# GPT-OSS API base URL
GPT_OSS_BASE_URL=http://localhost:8080

# --- Google Gemini (optional) ---
# Google Gemini API key for Gemini models
GEMINI_API_KEY=your-gemini-key

# --- Mistral/Mixtral (optional) ---
# Mistral API key for Mixtral models
MIXTRAL_API_KEY=your-mistral-key

# Mistral organization ID
AILINUX_MIXTRAL_ORG_ID=org_xxx

# --- WordPress/bbPress Integration (optional) ---
# WordPress site URL (must include protocol)
WORDPRESS_URL=https://example.com

# WordPress username for authentication
WORDPRESS_USER=wp-user

# WordPress password or application password
WORDPRESS_PASSWORD=wp-pass

# --- Web Crawler Configuration ---
# Enable/disable crawler functionality
CRAWLER_ENABLED=true

# Maximum memory in bytes for in-RAM crawl buffer (256MB default)
CRAWLER_MAX_MEMORY_BYTES=268435456

# Flush interval in seconds for rotating JSONL shards (hourly default)
CRAWLER_FLUSH_INTERVAL=3600

# Retention period in days for JSONL training shards
CRAWLER_RETENTION_DAYS=30

# Directory for crawler training data
CRAWLER_TRAIN_DIR=data/crawler_spool/train